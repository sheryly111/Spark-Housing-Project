{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cec2ea5",
   "metadata": {},
   "source": [
    "# Cleaning Student Addresses and SAM CSV, formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d77a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "#open addresses csv\n",
    "df = pd.read_csv(\"addresses.csv\")\n",
    "df2 = pd.read_csv(\"SAM.csv\")\n",
    "df.head()\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting ears of interest, leases starting from 2018 to 2024\n",
    "years_of_interest = [ \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "pattern = '|'.join(years_of_interest)\n",
    "matching_rows = df[df['year'].str.contains(pattern, case=False, na=False)]\n",
    "SAM_matching_rows = df2[df2['last_edited_date'].str.contains(pattern, case=False, na=False)]    \n",
    "\n",
    "# Combine all address cols with a space delimiter\n",
    "matching_rows['full address'] = matching_rows['6a. street #'] + ' ' + matching_rows['6b. street name']+ ' ' + matching_rows['6c. street suffix']\n",
    "\n",
    "SAM_matching_rows = SAM_matching_rows.drop(columns = ['shape_wkt', 'POINT_X', 'POINT_Y', 'X_COORD', 'Y_COORD'])\n",
    "matching_rows = matching_rows.drop(columns=['6a. street #', '6b. street name', '6c. street suffix'])\n",
    "\n",
    "\n",
    "display(matching_rows)\n",
    "display(SAM_matching_rows)\n",
    "print(SAM_matching_rows.shape)\n",
    "unique_unis = df['university'].unique()\n",
    "print(unique_unis)\n",
    "\n",
    "#test_row = df.loc[(df['6a. street #'] == '10')& (df['6b. street name'] == 'Higgins') & (df['6c. street suffix'] == 'ST')\t]\n",
    "#display(test_row)\n",
    "\n",
    "matching_rows.to_csv('cleaned_student_addresses.csv', index=False)\n",
    "\n",
    "#one SAM ID FOR ONE LANDLORD\n",
    "list(SAM_matching_rows)\n",
    "#num unique landlords\n",
    "unique_landlords = SAM_matching_rows['SAM_ADDRESS_ID'].nunique()\n",
    "print(f'Number of unique landlords: {unique_landlords}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting ONLY sam ids from student addresses\n",
    "matching_rows = matching_rows.rename(columns={'full address': 'FULL_ADDRESS'})\n",
    "df_matched = matching_rows.merge(SAM_matching_rows, on='FULL_ADDRESS', how='inner')\n",
    "\n",
    "#keep only cols we want\n",
    "col_keep = ['6d. unit #',\n",
    " '6e. zip',\n",
    " '9. 5 or more undergrads/unit (y/n)',\n",
    " 'year',\n",
    " 'FULL_ADDRESS',\n",
    " 'SAM_ADDRESS_ID',\n",
    " 'BUILDING_ID',\n",
    " 'STREET_NUMBER',\n",
    " 'UNIT',\n",
    " 'ZIP_CODE',\n",
    " 'WARD',\n",
    " 'PARCEL',\n",
    " 'created_date',\n",
    " 'last_edited_date']\n",
    "\n",
    "df_matched = df_matched[col_keep]\n",
    "#unique student housing addresse\n",
    "num_unique_student_addresses = matching_rows['FULL_ADDRESS'].nunique()\n",
    "print(f'Number of unique student housing addresses: {num_unique_student_addresses}')\n",
    "list(df_matched.columns.values)\n",
    "df_matched.head()\n",
    "\n",
    "#to csv\n",
    "df_matched.to_csv('cleaned_student_addresses_SAM.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248ab4e",
   "metadata": {},
   "source": [
    "# MERGE ALL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad4e82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00c65b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched = pd.read_csv(\"cleaned_student_addresses_SAM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d4a8958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shery\\AppData\\Local\\Temp\\ipykernel_29332\\2620560508.py:3: DtypeWarning: Columns (2,6,7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  propassessments = pd.read_csv(\"cleaned_property_assessment.csv\")\n"
     ]
    }
   ],
   "source": [
    "threeoneone = pd.read_csv(\"cleaned_311_calls.csv\")\n",
    "bpviolations = pd.read_csv(\"cleaned_building_and_property_violations.csv\")\n",
    "propassessments = pd.read_csv(\"cleaned_property_assessment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5409968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "suffix_map = {\n",
    "    'street': 'st', 'st': 'st', 'st.': 'st',\n",
    "    'road': 'rd',   'rd': 'rd', 'rd.': 'rd',\n",
    "    'avenue': 'ave','ave': 'ave','ave.': 'ave',\n",
    "    'boulevard': 'blvd', 'blvd': 'blvd',\n",
    "    'drive': 'dr', 'dr': 'dr',\n",
    "    'lane': 'ln', 'ln': 'ln',\n",
    "    'court': 'ct','ct': 'ct',\n",
    "    'place': 'pl','pl': 'pl',\n",
    "    'circle': 'cir','cir': 'cir'\n",
    "}\n",
    "\n",
    "\n",
    "# Build a regex pattern to match street address ending with a known suffix\n",
    "suffix_pattern = '|'.join(suffix_map.keys())\n",
    "street_regex = re.compile(r'(\\d+\\s+[\\w\\s]+?\\s+(?:' + suffix_pattern + r'))', flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_addr(addr):\n",
    "    # lowercase & strip\n",
    "    \n",
    "    a = addr.lower().strip()\n",
    "    \n",
    "    # take everything BEFORE the first comma\n",
    "    a = a.split(',')[0]\n",
    "    \n",
    "    # remove punctuation (except spaces and digits)\n",
    "    a = re.sub(r'[^a-z0-9 ]', ' ', a)\n",
    "    \n",
    "    if pd.isna(addr):\n",
    "        return \"\"\n",
    "    match = street_regex.search(addr)\n",
    "    if not match:\n",
    "        return addr.lower().strip()  # fallback\n",
    "    street = match.group(1).lower().strip()\n",
    "    \n",
    "    # standardize suffix\n",
    "    parts = street.split()\n",
    "    last = parts[-1]\n",
    "    if last in suffix_map:\n",
    "        parts[-1] = suffix_map[last]\n",
    "    return \" \".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90c55cd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m propassessments[\u001b[33m'\u001b[39m\u001b[33mfull_address\u001b[39m\u001b[33m'\u001b[39m] = propassessments[\u001b[33m'\u001b[39m\u001b[33mfull_address\u001b[39m\u001b[33m'\u001b[39m].apply(normalize_addr)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m threeoneone[\u001b[33m'\u001b[39m\u001b[33mlocation\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mthreeoneone\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_addr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m bpviolations[\u001b[33m'\u001b[39m\u001b[33mfull_address\u001b[39m\u001b[33m'\u001b[39m] = bpviolations[\u001b[33m'\u001b[39m\u001b[33mfull_address\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).apply(normalize_addr)\n\u001b[32m      4\u001b[39m df_matched[\u001b[33m'\u001b[39m\u001b[33mFULL_ADDRESS\u001b[39m\u001b[33m'\u001b[39m] = df_matched[\u001b[33m'\u001b[39m\u001b[33mFULL_ADDRESS\u001b[39m\u001b[33m'\u001b[39m].apply(normalize_addr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shery\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shery\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shery\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shery\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shery\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mnormalize_addr\u001b[39m\u001b[34m(addr)\u001b[39m\n\u001b[32m     28\u001b[39m a = a.split(\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# remove punctuation (except spaces and digits)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m a = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m[^a-z0-9 ]\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pd.isna(addr):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shery\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\__init__.py:186\u001b[39m, in \u001b[36msub\u001b[39m\u001b[34m(pattern, repl, string, count, flags)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msub\u001b[39m(pattern, repl, string, count=\u001b[32m0\u001b[39m, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    180\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m.sub(repl, string, count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shery\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\__init__.py:280\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(pattern, flags)\u001b[39m\n\u001b[32m    277\u001b[39m _MAXCACHE2 = \u001b[32m256\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m _MAXCACHE2 < _MAXCACHE\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile\u001b[39m(pattern, flags):\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# internal: compile pattern\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(flags, RegexFlag):\n\u001b[32m    283\u001b[39m         flags = flags.value\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "propassessments['full_address'] = propassessments['full_address'].apply(normalize_addr)\n",
    "threeoneone['location'] = threeoneone['location'].apply(normalize_addr)\n",
    "bpviolations['full_address'] = bpviolations['full_address'].astype(str).apply(normalize_addr)\n",
    "df_matched['FULL_ADDRESS'] = df_matched['FULL_ADDRESS'].apply(normalize_addr)\n",
    "\n",
    "#normalize name\n",
    "propassessments = propassessments.rename(columns={'full_address': 'FULL_ADDRESS'})\n",
    "bpviolations = bpviolations.rename(columns={'full_address': 'FULL_ADDRESS'})\n",
    "threeoneone = threeoneone.rename(columns={'location': 'FULL_ADDRESS'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpviolations['status_dttm'] = bpviolations['status_dttm'].astype(str).str[:4]\n",
    "bpviolations = bpviolations.rename(columns={'status_dttm':'year'})\n",
    "bpviolations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threeoneone['open_dt'] = threeoneone['open_dt'].astype(str).str[:4]\n",
    "threeoneone = threeoneone.rename(columns={'open_dt':'year'})\n",
    "threeoneone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2cd9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "propassessments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c0cbb",
   "metadata": {},
   "source": [
    "# MERGEMERGEMRG!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a966b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_matched.shape)\n",
    "print(propassessments.shape)\n",
    "print(threeoneone.shape)\n",
    "\n",
    "\n",
    "print(df_matched['FULL_ADDRESS'].duplicated().sum())\n",
    "print(propassessments['FULL_ADDRESS'].duplicated().sum())\n",
    "print(threeoneone['FULL_ADDRESS'].duplicated().sum())\n",
    "#df_merged = df_matched.merge(bpviolations, on=['FULL_ADDRESS', \"year\"], how='left').merge(propassessments, on='FULL_ADDRESS', how='left').merge(threeoneone, on=['FULL_ADDRESS', \"year\"], how='left')\n",
    "\n",
    "#print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched[\"year\"] = df_matched[\"year\"].astype(str).replace(\"nan\", \"\")\n",
    "threeoneone[\"year\"] = threeoneone[\"year\"].astype(str).replace(\"nan\", \"\")\n",
    "bpviolations[\"year\"] = bpviolations[\"year\"].astype(str).replace(\"nan\", \"\")\n",
    "propassessments[\"year\"] = propassessments[\"year\"].astype(str).replace(\"nan\", \"\")\n",
    "\n",
    "\n",
    "df_matched[\"FULL_ADDRESS\"] = df_matched[\"FULL_ADDRESS\"].astype(str).replace(\"nan\", \"\")\n",
    "threeoneone[\"FULL_ADDRESS\"] = threeoneone[\"FULL_ADDRESS\"].astype(str).replace(\"nan\", \"\")\n",
    "bpviolations[\"FULL_ADDRESS\"] = bpviolations[\"FULL_ADDRESS\"].astype(str).replace(\"nan\", \"\")\n",
    "\n",
    "df_matched[\"year\"] = df_matched[\"year\"].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590241e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test = df_matched.copy()\n",
    "df_test = df_merged_test.merge(threeoneone, on=['FULL_ADDRESS', \"year\"], how='left')\n",
    "df_test_2 = df_test.merge(propassessments, on=['FULL_ADDRESS', \"year\"], how='left')\n",
    "df_merge_total = df_test_2.merge(bpviolations, on=['FULL_ADDRESS', \"year\"], how='left')\n",
    "\n",
    "print(df_merge_total.shape)\n",
    "list(df_merge_total.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over_5               2823596\n",
      "year                       0\n",
      "full_address               0\n",
      "sam_id                     0\n",
      "building_id                0\n",
      "ward_id                    0\n",
      "parcel_num                 0\n",
      "case_created_date          6\n",
      "last_case_update           0\n",
      "targeted_deadline     433129\n",
      "close_date            218100\n",
      "case_met_deadline      17041\n",
      "case_status            17034\n",
      "closure_reason         17034\n",
      "case_title             17034\n",
      "case_subject           17034\n",
      "case_reason            17034\n",
      "case_type              17034\n",
      "case_department        17034\n",
      "p_id                  272831\n",
      "cm_id                 353065\n",
      "gis_id                273139\n",
      "landlord_name         272929\n",
      "int_cond              869430\n",
      "ext_cond              812265\n",
      "overall_cond          308394\n",
      "bdrm_cond             907120\n",
      "heat_type             869427\n",
      "ac_type               869426\n",
      "num_bed_rms           830838\n",
      "_id_y                3015986\n",
      "case_no              3015986\n",
      "ap_case_defn_key     3015986\n",
      "status               3015986\n",
      "code                 3015986\n",
      "value                3092491\n",
      "description          3015987\n",
      "violation_sthigh     3071481\n",
      "ward_y               3015986\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_drop = [\n",
    "    '6d. unit #', \n",
    "    '6e. zip',\n",
    "    'STREET_NUMBER', \n",
    "    'UNIT',\n",
    "    'ZIP_CODE',\n",
    "    '_id_x',\n",
    "    'case_enquiry_id',\n",
    "    'queue',\n",
    "    'pwd_district',\n",
    "    'neighborhood',\n",
    "    'neighborhood_services_district',\n",
    "    'ward_x',\n",
    "    'UNIT_NUM',\n",
    "    \"violation_sthigh\",\n",
    "    'ward_y',\n",
    "    '_id_y',\n",
    "    'case_no',\n",
    "    'ap_case_defn_key',\n",
    "    'status',\n",
    "    'code',\n",
    "    'value',\n",
    "    'description']\n",
    "df_merged = df_merge_total.drop(final_drop, axis=1)\n",
    "\n",
    "df_merged = df_merged.rename(columns={'9. 5 or more undergrads/unit (y/n)':'over_5'}) \n",
    "df_merged = df_merged.rename(columns={'FULL_ADDRESS':'full_address'}) \n",
    "df_merged = df_merged.rename(columns={'SAM_ADDRESS_ID':'sam_id'}) \n",
    "df_merged = df_merged.rename(columns={'BUILDING_ID':'building_id'}) \n",
    "df_merged = df_merged.rename(columns={'WARD':'ward_id'}) \n",
    "df_merged = df_merged.rename(columns={'PARCEL':'parcel_num'}) \n",
    "df_merged = df_merged.rename(columns={'created_date':'case_created_date'}) \n",
    "df_merged = df_merged.rename(columns={'last_edited_date':'last_case_update'}) \n",
    "df_merged = df_merged.rename(columns={'sla_target_dt':'targeted_deadline'}) \n",
    "df_merged = df_merged.rename(columns={'closed_dt':'close_date'}) \n",
    "df_merged = df_merged.rename(columns={'on_time':'case_met_deadline'}) \n",
    "df_merged = df_merged.rename(columns={'subject':'case_subject'}) \n",
    "df_merged = df_merged.rename(columns={'reason':'case_reason'}) \n",
    "df_merged = df_merged.rename(columns={'type':'case_type'}) \n",
    "df_merged = df_merged.rename(columns={'department':'case_department'}) \n",
    "\n",
    "df_merged = df_merged.rename(columns={'PID':'p_id'}) \n",
    "df_merged = df_merged.rename(columns={'CM_ID':'cm_id'}) \n",
    "df_merged = df_merged.rename(columns={'GIS_ID':'gis_id'}) \n",
    "df_merged = df_merged.rename(columns={'OWNER':'landlord_name'}) \n",
    "df_merged = df_merged.rename(columns={'INT_COND':'int_cond'}) \n",
    "df_merged = df_merged.rename(columns={'EXT_COND':'ext_cond'}) \n",
    "df_merged = df_merged.rename(columns={'OVERALL_COND':'overall_cond'}) \n",
    "df_merged = df_merged.rename(columns={'BDRM_COND':'bdrm_cond'}) \n",
    "df_merged = df_merged.rename(columns={'HEAT_TYPE':'heat_type'}) \n",
    "df_merged = df_merged.rename(columns={'AC_TYPE':'ac_type'}) \n",
    "df_merged = df_merged.rename(columns={'BED_RMS':'num_bed_rms'}) \n",
    "\n",
    "list(df_merged.columns.values)\n",
    "\n",
    "print(df_merged.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10f1d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3092491, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "Name: ward_y, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_merged.shape)\n",
    "df_merged['ward_y'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8996b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"raw_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066723c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_merged = pd.read_csv(\"raw_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41073dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories = df_merged['overall_cond'].unique()\n",
    "\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792428c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
